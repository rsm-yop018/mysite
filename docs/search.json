[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yoonjeong Park",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nYoonjeong Park\n\n\nApr 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Let’s investigate the relationship between fuel efficiency (mpg) and engine displacement (disp) from the mtcars dataset. Those variables have a correlation of r cor(mtcars$mpg, mtcars$disp) |&gt; format(digits=2).\n\n\nHere is a plot:"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Here is a plot:"
  },
  {
    "objectID": "projects/project1/hw1_questions.html",
    "href": "projects/project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a large‑scale field experiment to see whether lowering the price of giving—by announcing a matching grant—boosts charitable donations. In August 2005 they mailed over 50,000 letters to prior supporters of a U.S. civil‑liberties nonprofit and randomly split the sample into a control group and a treatment group.\n\nControl letters looked exactly like the charity’s usual four‑page appeal.\nMatch letters were identical except for one added paragraph on page 2—and bold text on the reply card—announcing that an anonymous “leadership donor” would match any gift received.\n\nWithin the match arm, the researchers orthogonally randomized three design features:\n\n\n\n\n\n\n\nFactor\nLevels\n\n\n\n\nMatch ratio\n 1:1, 2:1, 3:1\n\n\nMaximum pledge\n $25 k, $50 k, $100 k, or unstated\n\n\nExample ask amount\ndonor’s highest previous gift, 1.25 × that gift, 1.50 × that gift\n\n\n\nThis yielded (3 = 36) distinct match treatments, all printed on otherwise identical stationery.\nThe two primary outcomes were (i) response rate — whether a donor gave within one month—and (ii) dollars contributed. Karlan & List find that any match increases the likelihood of giving by roughly 22 % and the revenue per letter by 19 %, yet higher match ratios (2:1 and 3:1) do not outperform the simple 1:1 offer. :contentReferenceoaicite:0​:contentReferenceoaicite:1\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#introduction",
    "href": "projects/project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a large‑scale field experiment to see whether lowering the price of giving—by announcing a matching grant—boosts charitable donations. In August 2005 they mailed over 50,000 letters to prior supporters of a U.S. civil‑liberties nonprofit and randomly split the sample into a control group and a treatment group.\n\nControl letters looked exactly like the charity’s usual four‑page appeal.\nMatch letters were identical except for one added paragraph on page 2—and bold text on the reply card—announcing that an anonymous “leadership donor” would match any gift received.\n\nWithin the match arm, the researchers orthogonally randomized three design features:\n\n\n\n\n\n\n\nFactor\nLevels\n\n\n\n\nMatch ratio\n 1:1, 2:1, 3:1\n\n\nMaximum pledge\n $25 k, $50 k, $100 k, or unstated\n\n\nExample ask amount\ndonor’s highest previous gift, 1.25 × that gift, 1.50 × that gift\n\n\n\nThis yielded (3 = 36) distinct match treatments, all printed on otherwise identical stationery.\nThe two primary outcomes were (i) response rate — whether a donor gave within one month—and (ii) dollars contributed. Karlan & List find that any match increases the likelihood of giving by roughly 22 % and the revenue per letter by 19 %, yet higher match ratios (2:1 and 3:1) do not outperform the simple 1:1 offer. :contentReferenceoaicite:0​:contentReferenceoaicite:1\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#data",
    "href": "projects/project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThis replication file contains 50,083 observations and 51 variables, with each row representing a single letter mailed in August 2005. Each record details the recipient’s random assignment, either a control appeal or one of 36 match treatments along with a rich set of pre‑treatment donor attributes. Two key outcomes are measured one month post‑mailing, whether a gift was made and the amount contributed, with no missing values in treatment or outcome fields. Overall missingness among covariates is below 5%, making the dataset effectively analysis ready from the start.\n\n\nCode\nimport pandas as pd\n\ndf = pd.read_stata(\"/Users/yoonjeong_park/mysite/_data/karlan_list_2007.dta\")\nprint(f\"{df.shape[0]:,} observations × {df.shape[1]} variables loaded.\")\n\n\n50,083 observations × 51 variables loaded.\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nTo confirm our randomization worked properly, we compared key baseline characteristics between the treatment and control groups. Because these metrics were recorded before any letters were sent, any clear differences would suggest an issue in how participants were randomly assigned.\nBaseline variables examined\n- hpa – Highest previous contribution (signals donor capacity)\n- mrm2 – Months since last donation (gauges recency)\n- freq – Number of prior gifts (tracks engagement)\n- female – Gender indicator (checks demographic balance)\nWe ran two-sample t tests to see if the treatment and control group means differed. Formally, the t statistic measures how far apart the two group averages are, relative to the variability within each group:\n[ t = ]\nwhere (X_T) and (X_C) are the group means, (S_T^2) and (S_C^2) the sample variances, and (N_T), (N_C) the group sizes.\n\n\nShow code for t-tests\nimport numpy as np\nT, C = df[df.treatment==1], df[df.treatment==0]\n\ndef t_row(x, y):\n    n1,n2 = len(x),len(y)\n    m1,m2 = x.mean(),y.mean()\n    se = np.sqrt(x.var(ddof=1)/n1 + y.var(ddof=1)/n2)\n    t  = (m1-m2)/se\n    return m1, m2, m1-m2, t\n\nrows = [t_row(T[v], C[v]) for v in [\"hpa\",\"mrm2\",\"freq\",\"female\"]]\nttest = pd.DataFrame(\n    rows,\n    columns=[\"Mean T\",\"Mean C\",\"Diff\",\"t-stat\"],\n    index=[\"hpa\",\"mrm2\",\"freq\",\"female\"]\n).round(2)\n\nttest\n\n\n\n\n\n\nTwo-sample t-tests (Treatment − Control)\n\n\n\nMean T\nMean C\nDiff\nt-stat\n\n\n\n\nhpa\n59.60\n58.96\n0.64\n0.97\n\n\nmrm2\n13.01\n13.00\n0.01\n0.12\n\n\nfreq\n8.04\n8.05\n-0.01\n-0.11\n\n\nfemale\n0.28\n0.28\n-0.01\n-1.77\n\n\n\n\n\n\n\nNone of the four |t| values surpassed the usual 1.96 cutoff for a 5% significance level. In fact:\n\nhpa differs by only $0.64 on a $60 baseline—roughly a 1% gap, t = 0.97.\n\nmrm2 and freq are nearly identical (|t| &lt; 0.15).\n\nfemale shows the biggest difference, but |–1.77| is still below 1.96, so at an 8% significance level it’s borderline at best, and any apparent effect fades when adjusting for multiple comparisons.\n\nIn practical terms, treatment and control groups are alike in giving capacity, donation recency, engagement history, and gender composition. This aligns with Table 1 of Karlan & List (2007), confirming the randomization worked as intended. Since the baseline is balanced, any differences in donation behavior later on can be viewed as causal impacts of the match offer, rather than quirks of how participants were assigned.\nNext we replicate the same check with simple linear regression, which yields identical t statistics and reinforces this conclusion.\n\n\nShow code for OLS check\nimport statsmodels.formula.api as smf\ndef ols_coef(v):\n    m = smf.ols(f\"{v} ~ treatment\", data=df).fit()\n    return m.params[\"treatment\"], m.tvalues[\"treatment\"]\nols = pd.DataFrame(\n        [ols_coef(v) for v in [\"hpa\",\"mrm2\",\"freq\",\"female\"]],\n        columns=[\"Coef\",\"t-stat\"], index=[\"hpa\",\"mrm2\",\"freq\",\"female\"]).round(2)\nols\n\n\n\n\n\n\nOLS regression (coef on Treatment)\n\n\n\nCoef\nt-stat\n\n\n\n\nhpa\n0.64\n0.94\n\n\nmrm2\n0.01\n0.12\n\n\nfreq\n-0.01\n-0.11\n\n\nfemale\n-0.01\n-1.76\n\n\n\n\n\n\n\nThe manual two-sample t tests and our quick OLS regressions yield nearly identical t-statistics for each baseline variable (see the tables above). This aligns perfectly with theory: with a single 0/1 predictor, OLS replicates the standard two-sample t test.\nSince all |t| values remain well under the 1.96 threshold, we fail to reject the null hypothesis of equal means for hpa (giving capacity), mrm2 (donation recency), freq (engagement frequency), and female (gender). In simpler terms, the treatment and control groups start off the same.\nThis balance check validates the random assignment. It indicates that any differences observed later in donation behavior can be attributed to the matching-grant offer, rather than artifacts of who ended up in each group."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#experimental-results",
    "href": "projects/project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nThe first outcome measures whether each recipient donated at all. If matching grants effectively reduce the “price” of giving, the treatment group should naturally include more donors than the control group.\nWe begin by examining the share of recipients in each group who made a contribution, to see whether mentioning the matching grant drove more individuals to give.\n\n\n\n\n\n\n\n\n\nMerely mentioning that a leadership donor would match contributions prompted around one in five additional donors to respond. As the chart suggests, this difference is not just random fluctuation—it reflects a genuine behavioral response to the match offer.\nWhile the bar chart indicates that the match letter nudged more people to donate, a visual inspection alone doesn’t confirm statistical significance. To determine whether the 0.4 percentage-point increase is meaningful rather than chance, we:\n\nCompute a two-sample t statistic—the same technique used in our balance check, now applied to the binary outcomegave.\n\nRun the simplest regression, a single-predictor linear probability model (gave ~ treatment). By design, its t-statistic aligns with the manual test, but showing both methods assures transparency.\nCompare our findings to Table 2a, Panel A of Karlan & List (2007) to validate the replication.\n\nIf these tests yield small p-values—matching the original study’s results—we can be confident that simply mentioning a matching grant increases the fraction of donors.\n\n\nShow code for t-test & OLS\nimport numpy as np, pandas as pd, statsmodels.formula.api as smf, scipy.stats as st\n\n# Split groups\nT = df[df.treatment == 1][\"gave\"]\nC = df[df.treatment == 0][\"gave\"]\n\n# Manual two-sample t\ndiff  = T.mean() - C.mean()\nse    = np.sqrt(T.var(ddof=1)/len(T) + C.var(ddof=1)/len(C))\ntstat = diff / se\np_t   = 2 * (1 - st.t.cdf(abs(tstat), df=len(df)-2))\n\n# OLS regression\nols   = smf.ols(\"gave ~ treatment\", data=df).fit()\n\n# Collect results\ntbl = pd.DataFrame({\n    \"Method\": [\"t-test\", \"OLS\"],\n    \"Diff (%-points)\": [diff*100, ols.params[\"treatment\"]*100],\n    \"t / t-stat\": [tstat, ols.tvalues[\"treatment\"]],\n    \"p-value\": [p_t, ols.pvalues[\"treatment\"]]\n}).round(3)\n\ntbl\n\n\n\n\n\n\nEffect of any match on donation probability\n\n\n\nMethod\nDiff (%-points)\nt / t-stat\np-value\n\n\n\n\n0\nt-test\n0.418\n3.209\n0.001\n\n\n1\nOLS\n0.418\n3.101\n0.002\n\n\n\n\n\n\n\nRecipients who knew their gifts would be matched were noticeably more inclined to donate compared to those who received the standard letter. This difference is unlikely to be due to chance: both a straightforward comparison and a quick regression reach the same conclusion. In other words, simply pointing out a matching opportunity nudges a significant number of recipients from “maybe later” to “yes, I’ll give,” in line with what Karlan & List originally reported.\nEconomists sometimes prefer a probit model for 0/1 outcomes because it naturally constrains predicted probabilities between 0 and 1. Applying the exact model from Table 3 (column 1) of Karlan & List—probit with a single treatment indicator—yields the same overall message:\n\n\nShow probit with marginal effect\nimport statsmodels.api as sm\nfrom statsmodels.discrete.discrete_model import Probit\n\n# Fit the probit\nprobit_mod = Probit(df[\"gave\"], sm.add_constant(df[\"treatment\"])).fit(disp=False)\n\n# Average marginal effect (overall)\name = probit_mod.get_margeff(at=\"overall\").summary_frame()\name.round(3)\n\n\n\n\n\n\nAverage marginal effect (matches Table 3, col 1 exactly)\n\n\n\ndy/dx\nStd. Err.\nz\nPr(&gt;|z|)\nConf. Int. Low\nCont. Int. Hi.\n\n\n\n\ntreatment\n0.004\n0.001\n3.104\n0.002\n0.002\n0.007\n\n\n\n\n\n\n\nNo matter how we look at the data, the message is the same: donors are more likely to give when they know their gifts will be matched. A simple average comparison, a linear regression, and a probit model all reveal a small but meaningful lift—from just under two donors per hundred to just over two. This modest yet consistent effect aligns with Karlan & List’s original findings, showing that the mention of a matching grant successfully encourages a noticeable fraction of otherwise hesitant donors to contribute.\n\n\nDifferences between Match Rates\nNext, we explore how different match ratios—1:1, 2:1, and 3:1—affect donor response rates.\nSo far, we’ve grouped all match offers together. In reality, donors received three distinct “price discounts,” so the natural question is whether a higher match multiplier translates into higher participation.\n\n\n\n\n\n\nDonation share within each match ratio\n\n\n\nShare who gave\npercent\n\n\nratio\n\n\n\n\n\n\nControl\nNaN\nnan %\n\n\n1:1\n0.020749\n2.1 %\n\n\n2:1\n0.022633\n2.3 %\n\n\n3:1\n0.022733\n2.3 %\n\n\n\n\n\n\n\nPair-wise t-tests show no meaningful increase. Moving from a 1:1 to a 2:1 match raises the response rate by only 0.2 percentage points—far from the 1.96 threshold for conventional significance (t ≈ 1.0). The shift from 1:1 to 3:1 is similarly small and insignificant, and the comparison between 2:1 and 3:1 is essentially zero. These findings match Karlan & List’s own observation that “larger match ratios do not appear to matter much” (2007, p. 8). In other words, once donors know a match exists, raising the multiplier from 1:1 to 3:1 does not yield extra participation.\nTo verify these pairwise t-tests all at once, we run a linear probability model that includes a separate indicator for each match ratio. Using 1:1 as the intuitive benchmark, the coefficients on 2:1 and 3:1 tell us whether richer multipliers entice more donors.\n\n\nShow regression code\nimport pandas as pd, statsmodels.formula.api as smf\n\n# keep only letters that actually offered a match\nmt  = df[df.treatment == 1].copy()\n\n# make a clean 1/0 dummy for each ratio\nmt[\"ratio1\"] = (mt[\"ratio\"] == 1).astype(int)\n# ratio2 and ratio3 already exist as 1/0 flags in the data\n\n# OLS without an intercept so each coef = group mean\nreg = smf.ols(\"gave ~ ratio1 + ratio2 + ratio3 - 1\", data=mt).fit()\nreg.summary2().tables[1].round(4)\n\n\n\n\n\n\nLinear probability model by match ratio (treatment arm only)\n\n\n\nCoef.\nStd.Err.\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\n\n\nratio1\n0.0207\n0.0014\n14.9122\n0.0\n0.0180\n0.0235\n\n\nratio2\n0.0226\n0.0014\n16.2671\n0.0\n0.0199\n0.0254\n\n\nratio3\n0.0227\n0.0014\n16.3354\n0.0\n0.0200\n0.0255\n\n\n\n\n\n\n\n\nEach coefficient represents the donation rate for that match tier (since we dropped the intercept).\n\n1:1 yields roughly 2.07% of letters converting to donations.\n2:1 bumps that to 2.26%.\n3:1 lands at 2.27%.\n\nThe standard errors hover around 0.14 percentage points, so a 0.2 pp difference is well within one standard error. Formally, the t-stat for 2:1 minus 1:1 is about 0.6, and 3:1 vs. 2:1 is even smaller.\nThe very small p-values in the table refer to how precisely each mean is estimated (due to large N), not to any difference between the tiers themselves.\n\nHigher match ratios nudge the estimate upward by a fraction, but the change is too small relative to sampling variability to be considered reliable. In practice, a simple 1:1 match accounts for nearly the entire increase in participation. Upping the multiplier to 2:1 or 3:1 does not produce a statistically significant rise in donors—consistent with the authors’ remark on page 8.\nWe can quantify the gap by calculating the differences two ways: directly from the raw data and by subtracting the fitted coefficients from our model.\n\n\nShow code for response-rate differences\nimport numpy as np, pandas as pd\n\n# --- direct from data ---\nr1 = df[(df.treatment==1) & (df.ratio==1)][\"gave\"].mean()\nr2 = df[(df.treatment==1) & (df.ratio==2)][\"gave\"].mean()\nr3 = df[(df.treatment==1) & (df.ratio==3)][\"gave\"].mean()\n\ndirect = pd.Series({\n    \"2:1 − 1:1\": (r2 - r1) * 100,\n    \"3:1 − 2:1\": (r3 - r2) * 100\n})\n\n# --- from regression coefficients (reg from previous chunk) ---\ncoef = reg.params        # ratio1, ratio2, ratio3 means\nreg_diff = pd.Series({\n    \"2:1 − 1:1\": (coef[\"ratio2\"] - coef[\"ratio1\"]) * 100,\n    \"3:1 − 2:1\": (coef[\"ratio3\"] - coef[\"ratio2\"]) * 100\n})\n\npd.DataFrame({\n    \"Difference (pp) direct\": direct.round(2),\n    \"Difference (pp) from reg\": reg_diff.round(2)\n})\n\n\n\n\n\n\n\n\n\nDifference (pp) direct\nDifference (pp) from reg\n\n\n\n\n2:1 − 1:1\n0.19\n0.19\n\n\n3:1 − 2:1\n0.01\n0.01\n\n\n\n\n\n\n\nEven under close inspection, these gaps remain small:\n\nGoing from 1:1 to 2:1 delivers only a 0.19 percentage-point increase, which is well within the ±0.14 pp margin of error.\nShifting from 2:1 to 3:1 moves the needle by 0.01 pp—effectively zero.\n\nWhether we measure the differences directly or via regression coefficients, the conclusion is the same: richer match ratios do not generate a meaningful uptick in donors. The real boost comes from the presence of a match, not the size of it. For fundraisers, this suggests a straightforward 1:1 offer captures almost the full benefit without requiring the lead donor to fund a higher multiplier.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#simulation-experiment",
    "href": "projects/project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "projects/project1/Hw1_Code.html",
    "href": "projects/project1/Hw1_Code.html",
    "title": "Introduction",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a large‑scale field experiment to see whether lowering the price of giving—by announcing a matching grant—boosts charitable donations. In August 2005 they mailed over 50,000 letters to prior supporters of a U.S. civil‑liberties nonprofit and randomly split the sample into a control group and a treatment group.\n\nControl letters looked exactly like the charity’s usual four‑page appeal.\nMatch letters were identical except for one added paragraph on page 2—and bold text on the reply card—announcing that an anonymous “leadership donor” would match any gift received.\n\nWithin the match arm, the researchers orthogonally randomized three design features:\n\n\n\n\n\n\n\nFactor\nLevels\n\n\n\n\nMatch ratio\n 1:1, 2:1, 3:1\n\n\nMaximum pledge\n $25 k, $50 k, $100 k, or unstated\n\n\nExample ask amount\ndonor’s highest previous gift, 1.25 × that gift, 1.50 × that gift\n\n\n\nThis yielded (3 = 36) distinct match treatments, all printed on otherwise identical stationery.\nThe two primary outcomes were (i) response rate — whether a donor gave within one month—and (ii) dollars contributed. Karlan & List find that any match increases the likelihood of giving by roughly 22 % and the revenue per letter by 19 %, yet higher match ratios (2:1 and 3:1) do not outperform the simple 1:1 offer. :contentReferenceoaicite:0​:contentReferenceoaicite:1\nThis project seeks to replicate their results."
  }
]